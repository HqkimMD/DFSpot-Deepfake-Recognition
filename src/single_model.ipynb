{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "from blazeface import FaceExtractor, BlazeFace, VideoReader\n",
    "from architectures import fornet\n",
    "from architectures.fornet import FeatureExtractor\n",
    "from utils import utils\n",
    "from utils.utils import get_transformer\n",
    "from utils.utils import plot_confusion_matrix\n",
    "sys.path.append('..')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select architecture, device, face policy, face size, frames per video, dataset and provide model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_choices = ['TimmV2', 'TimmV2ST', 'ViT', 'ViTST']\n",
    "choices = {'v2': 'TimmV2', 'v2st': 'TimmV2ST', 'vit': 'ViT', 'vitst': 'ViTST'}\n",
    "device = torch.device(\n",
    "    'cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "face_policy = 'scale'\n",
    "face_size = 224\n",
    "frames_per_video = 32\n",
    "\n",
    "dataset = \"ffpp\"\n",
    "net_name = net_choices[0]\n",
    "net_class = getattr(fornet, net_name)\n",
    "model_path = \"../models/\" + dataset + \"_\" + \"v2.pth\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provide path to video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths = glob('../sample_videos/ffpp/real/**/*.mp4', recursive=True)\n",
    "file_names = []\n",
    "for i in video_paths:\n",
    "    file_names.append(i.split(\"/\")[4])\n",
    "file_names.sort()\n",
    "len(file_names)\n",
    "file_names\n",
    "\n",
    "video_idxs = [1, 3]\n",
    "\n",
    "input_dir = '../sample_videos/ffpp/real/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net: FeatureExtractor = net_class().eval().to(device)\n",
    "net.load_state_dict(torch.load(model_path, map_location='cpu')['net'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load face extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf = utils.get_transformer(\n",
    "    face_policy, face_size, net.get_normalizer(), train=False)\n",
    "facedet = BlazeFace().to(device)\n",
    "facedet.load_weights(\"blazeface/blazeface.pth\")\n",
    "facedet.load_anchors(\"blazeface/anchors.npy\")\n",
    "videoreader = VideoReader(verbose=False)\n",
    "\n",
    "\n",
    "def video_read_fn(x): return videoreader.read_frames(\n",
    "    x, num_frames=frames_per_video)\n",
    "\n",
    "\n",
    "face_extractor = FaceExtractor(video_read_fn=video_read_fn, facedet=facedet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_extractor.process_videos(\n",
    "    input_dir=input_dir, filenames=file_names, video_idxs=video_idxs)\n",
    "total_videos = len(video_idxs)\n",
    "\n",
    "\n",
    "faces_frames = [frames_per_video *\n",
    "                x for x in range(0, total_videos+1)]   # [0,32,64,96]\n",
    "\n",
    "faces_hc = torch.stack([transf(image=frame['faces'][0])['image']\n",
    "                       for frame in faces if len(frame['faces'])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "with torch.no_grad():\n",
    "    for i in range(0, total_videos):  # (0,3) i.e 0,1,2\n",
    "        pred = net(faces_hc[faces_frames[i]:faces_frames[i+1]\n",
    "                            ].to(device)).cpu().numpy().flatten()\n",
    "        score = expit(pred.mean())\n",
    "        predictions[input_dir+file_names[video_idxs[i]]\n",
    "                    ] = [round(score, 3), 'real' if score < 0.1 else 'fake']\n",
    "        predictions[input_dir+file_names[video_idxs[i]]] = [round(score, 3), {\n",
    "            'predicted_class': 'real' if score < 0.1 else 'fake', 'true_class': input_dir.split(\"/\")[3]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'../sample_videos/ffpp/real/091.mp4': [0.006,\n",
       "  {'predicted_class': 'real', 'true_class': 'real'}],\n",
       " '../sample_videos/ffpp/real/250.mp4': [0.002,\n",
       "  {'predicted_class': 'real', 'true_class': 'real'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass = []\n",
    "tclass = []\n",
    "res = []  # [   [predicted_class,true_class],    [predicted_class,true_class]     ....  ]\n",
    "for preds in predictions:\n",
    "    predicted_class = predictions[preds][1]['predicted_class']\n",
    "    true_class = predictions[preds][1]['true_class']\n",
    "    res.append([predicted_class, true_class])\n",
    "    pclass.append(predicted_class)\n",
    "    tclass.append(true_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(pclass)):\n",
    "    if(pclass[i] == 'real'):\n",
    "        pclass[i] = 0\n",
    "    elif(pclass[i] == 'fake'):\n",
    "        pclass[i] = 1\n",
    "\n",
    "pclass = torch.Tensor(pclass)\n",
    "\n",
    "for i in range(0, len(tclass)):\n",
    "    if(tclass[i] == 'real'):\n",
    "        tclass[i] = 0\n",
    "    elif(tclass[i] == 'fake'):\n",
    "        tclass[i] = 1\n",
    "tclass = torch.Tensor(tclass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = torch.stack((tclass, pclass), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmt = torch.zeros(2, 2, dtype=torch.int64)\n",
    "for p in stacked:\n",
    "    tl, pl = p.tolist()\n",
    "    cmt[int(tl), int(pl)] = cmt[int(tl), int(pl)] + 1\n",
    "cmt = cmt.detach().cpu().numpy()\n",
    "cmt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ('real', 'fake')\n",
    "plt.figure(figsize=(4, 4))\n",
    "plot_confusion_matrix(cmt, names)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
